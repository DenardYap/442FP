{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from dataloader import Dataset442FP \n",
    "from CNN442FP import ImageCNNRaw\n",
    "from Transformer442FP import LipReadingTransformer\n",
    "import torch\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gc\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "from greg_script import *\n",
    "import sys\n",
    "import random\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(69)\n",
    "np.random.seed(69)\n",
    "random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of files found for ./datasets/visual_data/ABOUT/train is 1000\n",
      "Num of files found for ./datasets/visual_data/BECAUSE/train is 1000\n",
      "Num of files found for ./datasets/visual_data/CALLED/train is 1000\n",
      "Num of files found for ./datasets/visual_data/DAVID/train is 1000\n",
      "Num of files found for ./datasets/visual_data/EASTERN/train is 1000\n",
      "Num of files found for ./datasets/visual_data/ABOUT/val is 50\n",
      "Num of files found for ./datasets/visual_data/BECAUSE/val is 50\n",
      "Num of files found for ./datasets/visual_data/CALLED/val is 50\n",
      "Num of files found for ./datasets/visual_data/DAVID/val is 50\n",
      "Num of files found for ./datasets/visual_data/EASTERN/val is 50\n",
      "Num of files found for ./datasets/visual_data/ABOUT/test is 50\n",
      "Num of files found for ./datasets/visual_data/BECAUSE/test is 50\n",
      "Num of files found for ./datasets/visual_data/CALLED/test is 50\n",
      "Num of files found for ./datasets/visual_data/DAVID/test is 50\n",
      "Num of files found for ./datasets/visual_data/EASTERN/test is 50\n",
      "(1000, 29, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classes = [\"ABOUT\", \"BECAUSE\", \"CALLED\", \"DAVID\", \"EASTERN\"]\n",
    "\n",
    "def formatData(image_name, partition): \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Given an image_name, find the respective .npz file in the directory \n",
    "    and format it in the format that the dataLoader expected\n",
    "\n",
    "    \n",
    "    image_name : str - the path to the image \n",
    "    partition : str - either train, test, or val \n",
    "    returns : a numpy array in shape N x 29 x 96 x 96 \n",
    "    \"\"\"\n",
    "    assert partition == \"train\" or partition == \"test\" or partition == \"val\"\n",
    "    image_name = image_name.upper()\n",
    "    dirPath = f\"./datasets/visual_data/{image_name}/{partition}\"\n",
    "    numOfFiles = os.listdir(dirPath)\n",
    "    print(f\"Num of files found for {dirPath} is {str(len(numOfFiles))}\")\n",
    "    res = []\n",
    "\n",
    "    for i in range(1, len(numOfFiles) + 1):\n",
    "        index = str(i).zfill(5)\n",
    "        npz_data = np.load(f'{dirPath}/{image_name}_{index}.npz')\n",
    "        res.append(npz_data[\"data\"])\n",
    "\n",
    "    return np.array(res, dtype=np.float32)\n",
    "\n",
    "train_ = {}\n",
    "val_ = {}\n",
    "test_ = {}\n",
    "for class_ in classes:\n",
    "    train_[class_] = formatData(class_, \"train\")\n",
    "for class_ in classes:\n",
    "    val_[class_] = formatData(class_, \"val\")\n",
    "for class_ in classes:\n",
    "    test_[class_] = formatData(class_, \"test\")\n",
    "print(train_[\"ABOUT\"].shape) # 1000 X 29 X 96 X 96 \n",
    "tr_loader = DataLoader(Dataset442FP(\"train\"), batch_size=64, shuffle=True)\n",
    "va_loader = DataLoader(Dataset442FP(\"val\"), batch_size=8, shuffle=False)\n",
    "te_loader = DataLoader(Dataset442FP(\"test\"), batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "# # Initialize model, loss function, and optimizer\n",
    "# model = LipReadingTransformer()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch, checkpoint_dir, stats, info):\n",
    "    \"\"\"Save a checkpoint file to checkpoint_dir.\"\"\"\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"stats\": stats}\n",
    "\n",
    "    name = \"b{b}_lr{lr}_p{p}_wd{wd}\".format(b = info[\"batch\"],\n",
    "                                                 lr = info[\"lr\"],\n",
    "                                                 p = info[\"p\"],\n",
    "                                                 wd = info[\"wd\"])\n",
    "\n",
    "    checkpoint_dir = os.path.join(checkpoint_dir, name)\n",
    "    checkpoint_dir = os.path.join(checkpoint_dir, \"checkpoints\")\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    filename = os.path.join(checkpoint_dir, f\"epoch={epoch}.checkpoint.pth.tar\")\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def trial(batch_size_in, learning_rate_in, momentum_in, weight_decay_in, save_folder, reg):\n",
    "    print(f'save_folder:{save_folder}')\n",
    "    \n",
    "    device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # tr_loader,va_loader,te_loader  = get_train_val_test_loaders(batch_size_in)\n",
    "    \n",
    "    # model = ImageCNNRaw()\n",
    "    model = LipReadingTransformer()\n",
    "    model.to(device)\n",
    "    \n",
    "    start_epoch = 0\n",
    "    stats = []\n",
    "    criterion = torch.nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate_in, weight_decay=weight_decay_in)\n",
    "\n",
    "    saved_path = os.path.join(save_folder,\n",
    "                              f\"b{batch_size_in}_lr{learning_rate_in}_p{momentum_in}_wd{weight_decay_in}\")\n",
    "    info = {\"batch\":batch_size_in, \"lr\":learning_rate_in,\"p\": momentum_in, \"wd\": weight_decay_in}\n",
    "    \n",
    "    if not os.path.exists(saved_path):\n",
    "        os.makedirs(saved_path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    print(\"inital eval\")\n",
    "    evaluate_epoch(tr_loader, va_loader, te_loader, model, criterion, start_epoch, stats,\n",
    "                   device,info, save_folder,reg)\n",
    "\n",
    "\n",
    "    global_min_loss = stats[-1][-2]\n",
    "    \n",
    "    patience = 5\n",
    "    curr_count_to_patience = 0\n",
    "    \n",
    "    # Loop over the entire dataset multiple times\n",
    "    epoch = start_epoch\n",
    "    print(f\"Entering train loop for lr:{learning_rate_in} p:{momentum_in} wd:{weight_decay_in}\")\n",
    "    while curr_count_to_patience < patience:\n",
    "        print(f\"starting epoch {epoch}\")\n",
    "        \n",
    "        # Train model\n",
    "        train_epoch(tr_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        # Evaluate model\n",
    "        evaluate_epoch(tr_loader, va_loader, te_loader,model, criterion, epoch + 1, stats,\n",
    "                       device, info, save_folder,reg)\n",
    "\n",
    "        # Save model parameters\n",
    "        save_checkpoint(model, epoch + 1, save_folder, stats, info)\n",
    "\n",
    "        if epoch > 8:\n",
    "            curr_count_to_patience, global_min_loss = early_stopping(stats, curr_count_to_patience, global_min_loss)\n",
    "        epoch += 1\n",
    "    print(f\"Finished Training after {epoch} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_folder:transformer_run\n",
      "inital eval\n",
      "torch.Size([1856, 1, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "trial(64, 5e-4, 0.9, 1e-4,'transformer_run',reg=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
